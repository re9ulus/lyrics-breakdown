{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.8075244024440723), (4, 0.5898341626740045)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [[(0, 1.0), (1, 1.0), (2, 1.0)],\n",
    "           [(2, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (8, 1.0)],\n",
    "           [(1, 1.0), (3, 1.0), (4, 1.0), (7, 1.0)],\n",
    "           [(0, 1.0), (4, 2.0), (7, 1.0)],\n",
    "           [(3, 1.0), (5, 1.0), (6, 1.0)],\n",
    "           [(9, 1.0)],\n",
    "           [(9, 1.0), (10, 1.0)],\n",
    "           [(9, 1.0), (10, 1.0), (11, 1.0)],\n",
    "           [(8, 1.0), (10, 1.0), (11, 1.0)]]\n",
    "\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "vec = [(0, 1), (4, 1)]\n",
    "tfidf[vec]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strings to Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "              \"A survey of user opinion of computer system response time\",\n",
    "              \"The EPS user interface management system\",\n",
    "              \"System and human system engineering testing of EPS\",\n",
    "              \"Relation of user perceived response time to error measurement\",\n",
    "              \"The generation of random binary unordered trees\",\n",
    "              \"The intersection graph of paths in trees\",\n",
    "              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "              \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'minors': 11, u'graph': 10, u'system': 6, u'trees': 9, u'eps': 8, u'computer': 1, u'survey': 5, u'user': 7, u'human': 2, u'time': 4, u'interface': 0, u'response': 3}\n",
      "[(1, 1), (2, 4)]\n"
     ]
    }
   ],
   "source": [
    "# remove stopwords\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "        for document in documents]\n",
    "\n",
    "# remove word that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text if frequency[token] > 1]\n",
    "        for text in texts]\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "print(dictionary.token2id)\n",
    "\n",
    "new_doc = 'Human computer interaction with human human human'\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "print(new_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(1, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(0, 1), (6, 1), (7, 1), (8, 1)],\n",
       " [(2, 1), (6, 2), (8, 1)],\n",
       " [(3, 1), (4, 1), (7, 1)],\n",
       " [(9, 1)],\n",
       " [(9, 1), (10, 1)],\n",
       " [(9, 1), (10, 1), (11, 1)],\n",
       " [(5, 1), (10, 1), (11, 1)]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BagWords\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('test.mm', corpus) # save to file for later use\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)]\n",
      "[(1, 0.44424552527467476), (3, 0.44424552527467476), (4, 0.44424552527467476), (5, 0.44424552527467476), (6, 0.3244870206138555), (7, 0.3244870206138555)]\n",
      "[(0, 0.5710059809418182), (6, 0.4170757362022777), (7, 0.4170757362022777), (8, 0.5710059809418182)]\n",
      "[(2, 0.49182558987264147), (6, 0.7184811607083769), (8, 0.49182558987264147)]\n",
      "[(3, 0.6282580468670046), (4, 0.6282580468670046), (7, 0.45889394536615247)]\n",
      "[(9, 1.0)]\n",
      "[(9, 0.7071067811865475), (10, 0.7071067811865475)]\n",
      "[(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)]\n",
      "[(5, 0.6282580468670046), (10, 0.45889394536615247), (11, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "for doc in corpus_tfidf:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"time\" + 0.060*\"response\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"'),\n",
       " (1,\n",
       "  u'-0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"response\" + -0.320*\"time\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2)\n",
    "corpus_lsi = lsi[corpus_tfidf]\n",
    "lsi.print_topics(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.066007833960902804), (1, -0.52007033063618502)]\n",
      "[(0, 0.19667592859142299), (1, -0.76095631677000519)]\n",
      "[(0, 0.089926399724463077), (1, -0.72418606267525143)]\n",
      "[(0, 0.075858476521780557), (1, -0.63205515860034334)]\n",
      "[(0, 0.10150299184979941), (1, -0.57373084830029586)]\n",
      "[(0, 0.70321089393783165), (1, 0.16115180214025668)]\n",
      "[(0, 0.87747876731198393), (1, 0.16758906864659256)]\n",
      "[(0, 0.90986246868185872), (1, 0.14086553628718854)]\n",
      "[(0, 0.6165825350569285), (1, -0.053929075663894835)]\n"
     ]
    }
   ],
   "source": [
    "for doc in corpus_lsi:\n",
    "    print(doc)\n",
    "# lsi.save('file_to_save.lsi')\n",
    "# lsi.load('file_to_load.lsi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similiarity Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.079104751174447582), (1, -0.57328352430794027)]\n"
     ]
    }
   ],
   "source": [
    "doc = 'Human computer interaction'\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]\n",
    "print(vec_lsi) # vec_lsi order by similiarity to vec_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beatles test\n",
    "TODO: Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "songs = []\n",
    "folder = './../data/beatles/'\n",
    "\n",
    "filenames = filter(lambda it: it.endswith('.txt'), os.listdir(folder))\n",
    "\n",
    "for name in filenames:\n",
    "    with open(folder + name, 'r') as f:\n",
    "        songs.append(re.sub(r'\\[.*\\]', '', f.read().replace('\\n',' ').strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.234*\"love\" + 0.165*\"i\" + 0.139*\"im\" + 0.138*\"you\" + 0.135*\"ill\" + 0.129*\"me\" + 0.123*\"she\" + 0.119*\"yeah\" + 0.118*\"her\" + 0.117*\"be\"'),\n",
       " (1,\n",
       "  u'-0.599*\"love\" + 0.232*\"back\" + 0.225*\"john\" + 0.163*\"brian\" + 0.119*\"get\" + -0.115*\"ill\" + -0.114*\"need\" + -0.111*\"true\" + 0.110*\"he\" + 0.110*\"paul\"')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [[word for word in song.translate(None, string.punctuation).lower().split()]\n",
    "        for song in songs]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.234*\"love\" + 0.165*\"i\" + 0.139*\"im\" + 0.139*\"you\" + 0.135*\"ill\" + 0.129*\"me\" + 0.123*\"she\" + 0.119*\"yeah\" + 0.118*\"her\" + 0.117*\"be\"'),\n",
       " (1,\n",
       "  u'-0.605*\"love\" + 0.233*\"back\" + 0.219*\"john\" + 0.152*\"brian\" + 0.122*\"get\" + -0.115*\"true\" + -0.114*\"need\" + -0.112*\"ill\" + 0.108*\"paul\" + 0.108*\"he\"'),\n",
       " (2,\n",
       "  u'-0.355*\"she\" + -0.307*\"her\" + 0.269*\"john\" + -0.206*\"shes\" + 0.193*\"brian\" + 0.151*\"needed\" + -0.125*\"does\" + 0.117*\"someone\" + -0.117*\"girl\" + -0.109*\"down\"'),\n",
       " (3,\n",
       "  u'-0.241*\"john\" + -0.227*\"love\" + -0.214*\"she\" + -0.198*\"her\" + -0.193*\"blackbird\" + -0.184*\"brian\" + 0.154*\"baby\" + 0.152*\"want\" + -0.145*\"moment\" + 0.143*\"cry\"'),\n",
       " (4,\n",
       "  u'0.342*\"blackbird\" + -0.316*\"yeah\" + -0.254*\"love\" + 0.247*\"fly\" + 0.240*\"moment\" + -0.217*\"john\" + 0.207*\"waiting\" + 0.196*\"arise\" + -0.181*\"brian\" + 0.136*\"only\"')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 5\n",
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=number_of_topics)\n",
    "lsi.print_topics(number_of_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 : 0.002*bird + 0.002*bye + 0.002*chains + 0.002*la + 0.002*birthday\n",
      "Topic 1 : 0.002*nah + 0.002*beep + 0.002*coo + 0.002*dr + 0.002*robert\n",
      "Topic 2 : 0.005*love + 0.004*i + 0.004*you + 0.004*im + 0.004*me\n",
      "Topic 3 : 0.002*harp + 0.002*dizzy + 0.002*mystery + 0.002*ussr + 0.002*roll\n",
      "Topic 4 : 0.002*commonwealth + 0.002*da + 0.002*tripper + 0.002*evrything + 0.002*bop\n"
     ]
    }
   ],
   "source": [
    "number_of_topics = 5\n",
    "lda = models.ldamodel.LdaModel(corpus_tfidf, id2word=dictionary,\n",
    "                               num_topics=number_of_topics,\n",
    "                               passes=20)\n",
    "\n",
    "\n",
    "for t, top_words in lda.print_topics(num_topics=number_of_topics, num_words=5):\n",
    "    print \"Topic\", t, \":\", top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1822!', [(2, 0.7134855435191424), (3, 0.265731891494497)])\n",
      "('A Day In The Life', [(2, 0.9139578570388539), (3, 0.083207853305271903)])\n",
      "(\"A Hard Day's Night\", [(2, 0.9967464099738873)])\n",
      "('A Little Rhyme', [(2, 0.99079081909550637)])\n",
      "('A Shot Of Rhythm And Blues', [(1, 0.089610437386146657), (2, 0.90847717317027243)])\n",
      "('A Taste Of Honey', [(2, 0.99291513980013879)])\n",
      "('Across The Universe', [(1, 0.35699346864690573), (2, 0.64003536173678643)])\n",
      "('Act Naturally', [(2, 0.91549908443542261), (3, 0.081635333131889726)])\n",
      "(\"Ain't She Sweet\", [(0, 0.060636108469957144), (2, 0.93598685491024902)])\n",
      "(\"All I've Got To Do\", [(2, 0.99499850721885164)])\n",
      "('All My Loving', [(2, 0.99466479547493669)])\n",
      "('All Things Must Pass', [(2, 0.99469455442273791)])\n",
      "('All Together Now', [(1, 0.15317303864486695), (2, 0.84415120268542987)])\n",
      "('All You Need Is Love', [(2, 0.99648810922580078)])\n",
      "('And I Love Her', [(2, 0.9923777251634488)])\n",
      "('And Your Bird Can Sing', [(2, 0.99254278562079168)])\n",
      "('Anna, Go To Him', [(2, 0.98918524520803319)])\n",
      "('Another Girl', [(2, 0.99591665786373984)])\n",
      "('Any Time At All', [(2, 0.99486997125483101)])\n",
      "('Ask Me Why', [(2, 0.99547912743883615)])\n"
     ]
    }
   ],
   "source": [
    "# Получение темы для конкретного документа\n",
    "\n",
    "for i in range(20):\n",
    "    print(filenames[i].replace('.txt', ''), lda[corpus[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
